{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salem Ameen, PhD student at Salford University\n",
    "\n",
    "###Â Boston House price\n",
    "\n",
    "Deep learning Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"70f4a05c-f0f5-4396-9e8e-165e854f9a39\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = \"1\";\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  var js_urls = ['https://cdn.pydata.org/bokeh/release/bokeh-0.12.1.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.1.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-compiler-0.12.1.min.js'];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      Bokeh.$(\"#70f4a05c-f0f5-4396-9e8e-165e854f9a39\").text(\"BokehJS successfully loaded\");\n",
       "      var kernel = Jupyter.notebook.kernel\n",
       "      if (kernel.execute !== undefined) {\n",
       "          kernel.execute(\"import bokeh.io; bokeh.io._nb_loaded = True\");\n",
       "      }\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.1.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.1.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.1.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.1.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i](window.Bokeh);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from numpy import *\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import feature_selection\n",
    " \n",
    "from sklearn.learning_curve import learning_curve, validation_curve\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn import metrics, grid_search, cross_validation\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from bokeh.layouts import gridplot\n",
    "output_notebook()\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (6, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define base mode\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(30, input_dim=13, init='normal', activation='relu'))\n",
    "\tmodel.add(Dense(1, init='normal'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous file we have not change the data as there is no missing value or add any new parameters so it can be downloaded from the web directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "feature_cols = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_csv(url, sep='\\s+', names = feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples 506\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "dataset = data.values\n",
    "X = dataset[:,0:13].astype(float)\n",
    "Y = dataset[:,13]\n",
    "print 'Number of examples',len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples 404\n",
      "Number of validation examples 102\n"
     ]
    }
   ],
   "source": [
    "# Make developement dataset for genrilization and final testing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# Extracting 20% testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.20, random_state=0)\n",
    "X = X_train\n",
    "Y = y_train\n",
    "new_data      = X_train\n",
    "new_test_data = X_test\n",
    "print 'Number of training examples',len(X_train)\n",
    "print 'Number of validation examples',len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "model = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=5, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n=len(X), n_folds=10, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(model, X, Y, cv=kfold)\n",
    "r_squared = r2_score(Y, predicted, multioutput='variance_weighted')\n",
    "print 'R-squared = ',r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking of the feature's importance to the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randing the important features to the target\n",
    "model = feature_selection.SelectKBest(score_func=feature_selection.f_regression,k=4)\n",
    "results = model.fit(data[feature_cols], data['MEDV'])\n",
    "k=0\n",
    "print 'Feature Name      Score         Pvalue'\n",
    "for feat in feature_cols:\n",
    "    print feat,'\\t\\t',results.scores_[k],'\\t',results.pvalues_[k]\n",
    "    k=k+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the parameters for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Set the parameters for bias-variance dilemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data and save both the model and preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# According to the nature of the data spasity and there is outliter RobustScaler class is recomandit \n",
    "# but when I tried both of them the result seems is same\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) # use same transform for testing data\n",
    "X = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save transformed data\n",
    "np.save('./data/X_train', X_train)\n",
    "np.save('./data/y_train', y_train)\n",
    "np.save('./data/X_test', X_test)\n",
    "np.save('./data/y_test', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the model scaler to the desk\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(scaler, 'scaler.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test the model if it is work\n",
    "scalerTest = joblib.load('scaler.pkl')\n",
    "new_data_scaled = scalerTest.transform(new_test_data)\n",
    "print \" =================================================================>>>>> done\"\n",
    "print new_data_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. model  with   Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning or the Classification and Regression Trees (CART as they are know) use the training data to select the best points to split the data in order to minimize a cost metric. The default cost metric for regression Deep learning is the mean squared error, specified in the criterion parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=13, init='normal', activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(1, init='normal'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# Actual modelling\n",
    "model.fit(X, Y, verbose=0, batch_size=9, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficients Of Determination {Calculating R^2}\n",
    "\n",
    "R^2, Close to one is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(X)\n",
    "r_squared = r2_score(Y, predicted, multioutput='variance_weighted')\n",
    "print 'R-squared = ',r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = predicted.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Y, predicted)\n",
    "ax.plot([Y.min(), Y.max()], [Y.min(), Y.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotining using bokeh\n",
    "#TOOLS = [BoxSelectTool(), HoverTool()]\n",
    "#TOOLS = 'hover,box_zoom,box_select,crosshair,resize,reset,model_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "TOOLS = 'box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "p = figure(plot_width=500, plot_height=500, tools=TOOLS)\n",
    "p.scatter(Y, prediction,x=\"jjj\", marker=\"o\", color=\"#80B1D3\", line_width=3)\n",
    "p.title.align = \"center\"\n",
    "p.xaxis.axis_label = \"Measured\"\n",
    "p.xaxis.axis_label_text_color = \"#aa6666\"\n",
    "#p.xaxis.axis_label_standoff = 30\n",
    "p.xaxis.major_tick_line_color = \"firebrick\"\n",
    "p.xaxis.major_tick_line_width = 3\n",
    "p.xaxis.minor_tick_line_color = \"orange\"\n",
    "p.yaxis.axis_label = \"Predicted\"\n",
    "p.yaxis.axis_label_text_font_style = \"italic\"\n",
    "p.yaxis.axis_label_text_color = \"#aa6666\"\n",
    "p.background_fill_color = \"beige\"\n",
    "p.background_fill_alpha = 0.5\n",
    "#p.line([Y.min(), Y.max()], [Y.min(), Y.max()], line_dash=\"4 4\", line_width=2, color='red')\n",
    "\n",
    "# create a new plot with the toolbar below\n",
    "# line_dash=\"4 4\", line_width=2, color='red'\n",
    "p.line([Y.min(), Y.max()], [Y.min(), Y.max()], line_dash=\"4 4\", line_width=2, line_color=\"black\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(predicted, (predicted.T - Y), c='r', s=30)\n",
    "plt.title(\"Residual plot on the training data\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotining using bokeh\n",
    "#TOOLS = 'hover,box_zoom,box_select,crosshair,resize,reset,model_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "TOOLS = 'box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "p = figure(plot_width=500, plot_height=500, title=\"Residual plot on the training data\", tools=TOOLS)\n",
    "p.scatter(prediction, (prediction - Y),x=\"jjj\", marker=\"o\", color=\"#80B1D3\", line_width=3)\n",
    "p.title.align = \"center\"\n",
    "p.xaxis.axis_label = \"Predicted\"\n",
    "p.xaxis.axis_label_text_color = \"#aa6666\"\n",
    "#p.xaxis.axis_label_standoff = 30\n",
    "p.xaxis.major_tick_line_color = \"firebrick\"\n",
    "p.xaxis.major_tick_line_width = 3\n",
    "p.xaxis.minor_tick_line_color = \"orange\"\n",
    "p.yaxis.axis_label = \"Residuals\"\n",
    "p.yaxis.axis_label_text_font_style = \"italic\"\n",
    "p.yaxis.axis_label_text_color = \"#aa6666\"\n",
    "p.background_fill_color = \"beige\"\n",
    "p.background_fill_alpha = 0.5\n",
    "#p.line([2,38], [0, 0], line_dash=\"4 4\", line_width=2, color='red')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using make_pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# ANOVA SVM-C\n",
    "# 1) anova filter, take 3 best ranked features\n",
    "DLRegressor = make_pipeline(scaler, model)\n",
    "DLRegressor.fit(new_data, Y)\n",
    "prediction = DLRegressor.predict(new_data)\n",
    "r_squared = r2_score(Y, prediction, multioutput='variance_weighted')\n",
    "print 'R-squared = ',r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Pipeline model for developement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I can save keras in pipleine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_weights('Boston_House_Modelbest.hdf5',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test the model if it is work\n",
    "model.load_weights('Boston_House_Modelbest.hdf5')\n",
    "\n",
    "NewPred = model.predict(X)\n",
    "print \" =================================================================>>>>> done\"\n",
    "r_squared = r2_score(Y, NewPred, multioutput='variance_weighted')\n",
    "print 'R-squared = ',r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test on single data point, randomly choose point number 55\n",
    "print 'Point of training data before normalization\\n',new_data[55]\n",
    "print '\\nThe read target of the data = ', Y[55]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test the model if it is work\n",
    "scalerTest = joblib.load('scaler.pkl')\n",
    "new_data_scaled = scalerTest.transform(new_data[55].reshape(1, -1))\n",
    "print \" =================================================================>>>>> done\"\n",
    "print new_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NewPred = model.predict(new_data_scaled, verbose=0)\n",
    "print '\\nThe Predicted target of the data = ', NewPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
