{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salem Ameen, PhD student at Salford University\n",
    "\n",
    "###Â Boston House price\n",
    "\n",
    "Kernel KernelRidge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"3c906686-ceb2-437a-8c68-78cf041fe4c5\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = \"1\";\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  var js_urls = ['https://cdn.pydata.org/bokeh/release/bokeh-0.12.1.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.1.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-compiler-0.12.1.min.js'];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      Bokeh.$(\"#3c906686-ceb2-437a-8c68-78cf041fe4c5\").text(\"BokehJS successfully loaded\");\n",
       "      var kernel = Jupyter.notebook.kernel\n",
       "      if (kernel.execute !== undefined) {\n",
       "          kernel.execute(\"import bokeh.io; bokeh.io._nb_loaded = True\");\n",
       "      }\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.1.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.1.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.1.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.1.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i](window.Bokeh);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from numpy import *\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import feature_selection\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.learning_curve import learning_curve, validation_curve\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn import metrics, grid_search, cross_validation\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from bokeh.layouts import gridplot\n",
    "output_notebook()\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (6, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous file we have not change the data as there is no missing value or add any new parameters so it can be downloaded from the web directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "feature_cols = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_csv(url, sep='\\s+', names = feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples 506\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "dataset = data.values\n",
    "X = dataset[:,0:13].astype(float)\n",
    "Y = dataset[:,13]\n",
    "print 'Number of examples',len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples 404\n",
      "Number of validation examples 102\n"
     ]
    }
   ],
   "source": [
    "# Make developement dataset for genrilization and final testing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# Extracting 20% testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.20, random_state=0)\n",
    "X = X_train\n",
    "Y = y_train\n",
    "new_data      = X_train\n",
    "new_test_data = X_test\n",
    "print 'Number of training examples',len(X_train)\n",
    "print 'Number of validation examples',len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of training data is very small so we need to use cross validation instead of spareate another validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous visulization the data has no missing value but has many outlier and some sparisty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking of the feature's importance to the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM \t-5.66303451728\n",
      "ZN \t-4.05708578855\n",
      "INDUS \t-2.64681157725\n",
      "CHAS \t-5.35211936952\n",
      "NOX \t-0.662755471713\n",
      "RM \t0.308091165186\n",
      "AGE \t-1.49438692403\n",
      "DIS \t-0.879138192382\n",
      "RAD \t-3.59317788546\n",
      "TAX \t-1.65243007552\n",
      "PTRATIO \t-0.365905893853\n",
      "B \t0.0302622632502\n",
      "LSTAT \t-2.86735798245\n",
      "MEDV \t0.999999999922\n"
     ]
    }
   ],
   "source": [
    "# Using just correlation coefficient even in prevoius file we show them using data frame\n",
    "for col in feature_cols:\n",
    "    lm = KernelRidge()\n",
    "    lm.fit(data[[col]], data['MEDV'])\n",
    "    print col,'\\t', lm.score(data[[col]], data['MEDV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Name      Score         Pvalue\n",
      "CRIM \t\t89.4861147577 \t1.17398708219e-19\n",
      "ZN \t\t75.257642299 \t5.71358415308e-17\n",
      "INDUS \t\t153.954883136 \t4.90025998175e-31\n",
      "CHAS \t\t15.9715124204 \t7.39062317052e-05\n",
      "NOX \t\t112.59148028 \t7.06504158625e-24\n",
      "RM \t\t471.846739876 \t2.48722887101e-74\n",
      "AGE \t\t83.4774592192 \t1.56998220919e-18\n",
      "DIS \t\t33.5795703259 \t1.20661172734e-08\n",
      "RAD \t\t85.9142776698 \t5.46593256965e-19\n",
      "TAX \t\t141.761356577 \t5.63773362769e-29\n",
      "PTRATIO \t\t175.105542876 \t1.60950947847e-34\n",
      "B \t\t63.0542291125 \t1.31811273408e-14\n",
      "LSTAT \t\t601.61787111 \t5.08110339439e-88\n",
      "MEDV \t\tinf \t0.0\n"
     ]
    }
   ],
   "source": [
    "# Randing the important features to the target\n",
    "model = feature_selection.SelectKBest(score_func=feature_selection.f_regression,k=4)\n",
    "results = model.fit(data[feature_cols], data['MEDV'])\n",
    "k=0\n",
    "print 'Feature Name      Score         Pvalue'\n",
    "for feat in feature_cols:\n",
    "    print feat,'\\t\\t',results.scores_[k],'\\t',results.pvalues_[k]\n",
    "    k=k+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the parameters for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Set the parameters for bias-variance dilemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data and save both the model and preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# According to the nature of the data spasity and there is outliter RobustScaler class is recomandit \n",
    "# but when I tried both of them the result seems is same\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) # use same transform for testing data\n",
    "X = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save transformed data\n",
    "np.save('./data/X_train', X_train)\n",
    "np.save('./data/y_train', y_train)\n",
    "np.save('./data/X_test', X_test)\n",
    "np.save('./data/y_test', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl', 'scaler.pkl_01.npy', 'scaler.pkl_02.npy', 'scaler.pkl_03.npy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model scaler to the desk\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(scaler, 'scaler.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " =================================================================>>>>> done\n",
      "[[-0.40835869 -0.49960763 -1.12872913 ..., -0.71272928  0.18547577\n",
      "  -0.73610347]\n",
      " [ 0.71925111 -0.49960763  0.9988844  ...,  0.79267419  0.0831649\n",
      "  -0.4356916 ]\n",
      " [-0.40257488 -0.49960763  0.39610829 ..., -0.94082071  0.39472748\n",
      "  -0.30263246]\n",
      " ..., \n",
      " [-0.3982601   0.55937182 -0.85812418 ...,  0.56458276  0.41019833\n",
      "   0.06087961]\n",
      " [-0.39934279 -0.49960763 -0.07637654 ...,  0.0627816   0.30517724\n",
      "  -0.45626776]\n",
      " [-0.40088071 -0.49960763 -0.36702631 ...,  1.1120022   0.41166637\n",
      "  -0.05983383]]\n"
     ]
    }
   ],
   "source": [
    "# Test the model if it is work\n",
    "scalerTest = joblib.load('scaler.pkl')\n",
    "new_data_scaled = scalerTest.transform(new_test_data)\n",
    "print \" =================================================================>>>>> done\"\n",
    "print new_data_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KernelRidge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel KernelRidge regression (KRR) combines KernelRidge regression (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choosing multiple hyperparameters of an estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kernel', 'degree', 'kernel_params', 'alpha', 'coef0', 'gamma']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "estimator = KernelRidge()\n",
    "estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-104:\n",
      "Process PoolWorker-107:\n",
      "Process PoolWorker-101:\n",
      "Process PoolWorker-103:\n",
      "Process PoolWorker-106:\n",
      "Process PoolWorker-108:\n",
      "Process PoolWorker-105:\n",
      "Process PoolWorker-102:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Applications/Canopy.app/appdata/canopy-1.7.4.3348.macosx-x86_64/Canopy.app/Contents/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "    task = get()\n",
      "    task = get()\n",
      "    task = get()\n",
      "    task = get()\n",
      "    task = get()\n",
      "    task = get()\n",
      "  File \"/Users/salemameen/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "    task = get()\n",
      "  File \"/Users/salemameen/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "  File \"/Users/salemameen/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "  File \"/Users/salemameen/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 359, in get\n",
      "  File \"/Users/salemameen/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "  File \"/Users/salemameen/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "  File \"/Users/salemameen/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "  File \"/Users/salemameen/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/sklearn/externals/joblib/pool.py\", line 357, in get\n",
      "    racquire()\n",
      "    racquire()\n",
      "    racquire()\n",
      "    return recv()\n",
      "    racquire()\n",
      "    racquire()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# For parametr gamma\n",
    "#param_range = np.logspace(-10.0, 10.0)\n",
    "#param_range = np.logspace(-20, 2, 50)\n",
    "param_range = np.linspace(0.00000000001,0.5,10)\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    KernelRidge(kernel='rbf'), X, Y, param_name=\"gamma\", param_range=param_range,\n",
    "    cv=num_folds,  n_jobs=-1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with KernelRidge\")\n",
    "plt.xlabel(\"gamma\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"g\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks gamma between 0 and 0.1 works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For parametr alpha\n",
    "#param_range = np.logspace(-10.0, 10.0)\n",
    "#param_range = np.logspace(-20, 2, 50)\n",
    "param_range = np.linspace(0,0.2,100)\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    KernelRidge(kernel='rbf'), X, Y, param_name=\"alpha\", param_range=param_range,\n",
    "    cv=num_folds,  n_jobs=-1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with KernelRidge\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.2, 1.0)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"g\")\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks very small alpha works fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search and/or Random search to determine best compination of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Utility function to report optimal parameters\n",
    "from operator import itemgetter\n",
    "def report(grid_scores, n_top=5):\n",
    "    params = None\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Parameters with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.4f} (std: {1:.4f})\".format(\n",
    "              score.mean_validation_score, np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "        \n",
    "        if params == None:\n",
    "            params = score.parameters\n",
    "    \n",
    "    return params\n",
    "\n",
    "# The most common value for the max number of features to look at in each split is sqrt(# of features)\n",
    "sqrtfeat = np.sqrt(X.shape[1]) \n",
    "# Simple grid test (162 combinations)\n",
    "grid_test1 = { \"gamma\"      : np.linspace(0.00000000001,0.2,20),\n",
    "               \"alpha\"         :  np.linspace(0.00000000000001,0.2,20) }\n",
    "\n",
    "# Large randomized test using max_depth to control tree size (5000 possible combinations)\n",
    "random_test1 = { \"gamma\"          : [0.0000000001, 0.0000002, 0.00003],\n",
    "                 \"alpha\"         : [0.000001, 0.1] }\n",
    "\n",
    "\n",
    "forest = KernelRidge(kernel='rbf')\n",
    "\n",
    "print \"Hyperparameter optimization using GridSearchCV...\"\n",
    "grid_search = GridSearchCV(forest, grid_test1, n_jobs=-1, cv=num_folds)\n",
    "grid_search.fit(X, Y)\n",
    "best_params_from_grid_search = report(grid_search.grid_scores_)\n",
    "print '+++++++++++++++++++++++++++++++++++++++++++++++'\n",
    "print \"Hyperparameter optimization using RandomizedSearchCV\"\n",
    "grid_search = RandomizedSearchCV(forest, random_test1, n_jobs=-1, cv=num_folds, n_iter=5)\n",
    "grid_search.fit(X, Y)\n",
    "best_params_from_rand_search1 = report(grid_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In essence, what weâre doing it training the exact same model with increasingly large fractions of our total training data, and plotting the error of the training and test sets at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "# 'alpha': 10.0, 'solver': 'lsqr'\n",
    "model = KernelRidge(kernel='rbf', gamma=0.052, alpha =  0.0216)\n",
    "title = \"Learning Curves (KernelRidge Refression)\"\n",
    "cv = cross_validation.ShuffleSplit(X.shape[0], n_iter=100,\n",
    "                                   test_size=0.2, random_state=0)\n",
    "plot_learning_curve(model, title, X, Y, ylim=(0.2, 1.01), cv=cv, n_jobs=-1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# More data from learning curve to show the process of building the model\n",
    "train_sizes, train_scores, valid_scores = learning_curve(\n",
    "     model, X, Y, train_sizes=[50, 80, 110], cv=cv, n_jobs=4)\n",
    "\n",
    "print 'train_sizes = ', train_sizes\n",
    "\n",
    "print ' training scores'\n",
    "print ' 50 training sizees'\n",
    "print train_scores[0].mean(),'Â±',train_scores[0].std()\n",
    "print ' 80 training sizees'\n",
    "print train_scores[1].mean(),'Â±',train_scores[1].std()\n",
    "print ' 110 training sizees'\n",
    "print train_scores[2].mean(),'Â±',train_scores[2].std()\n",
    "\n",
    "print '\\n validation scores'\n",
    "print ' 50 validation scores'\n",
    "print valid_scores[0].mean(),'Â±',valid_scores[0].std()\n",
    "print ' 80 validation scores'\n",
    "print valid_scores[1].mean(),'Â±',valid_scores[1].std()\n",
    "print ' 110 validation scores'\n",
    "print valid_scores[2].mean(),'Â±',valid_scores[2].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoring = 'mean_squared_error'\n",
    "results = cross_validation.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print 'Scoring according to mean_squared_error'\n",
    "print results\n",
    "print '\\n Mean      Standard deviation'\n",
    "print(\"%.2f      %.2f\" % (results.mean(), results.std()))\n",
    "## Fit the model\n",
    "model.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be more precise these valrible is not the input feature as descripe on the dataset, those varibles in scaled virsion on the orginal onces. So, to be more correct I should assign to them another varibles but for easy to unserstand I kept them as they were."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficients Of Determination {Calculating R^2}\n",
    "\n",
    "R^2, Close to one is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(model, X, Y, cv=kfold)\n",
    "r_squared = r2_score(Y, predicted, multioutput='variance_weighted')\n",
    "print 'R-squared = ',r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(model, X, Y, cv=kfold)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Y, predicted)\n",
    "ax.plot([Y.min(), Y.max()], [Y.min(), Y.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotining using bokeh\n",
    "#TOOLS = [BoxSelectTool(), HoverTool()]\n",
    "#TOOLS = 'hover,box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "TOOLS = 'box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "p = figure(plot_width=500, plot_height=500, tools=TOOLS)\n",
    "p.scatter(Y, predicted,x=\"jjj\", marker=\"o\", color=\"#80B1D3\", line_width=3)\n",
    "p.title.align = \"center\"\n",
    "p.xaxis.axis_label = \"Measured\"\n",
    "p.xaxis.axis_label_text_color = \"#aa6666\"\n",
    "#p.xaxis.axis_label_standoff = 30\n",
    "p.xaxis.major_tick_line_color = \"firebrick\"\n",
    "p.xaxis.major_tick_line_width = 3\n",
    "p.xaxis.minor_tick_line_color = \"orange\"\n",
    "p.yaxis.axis_label = \"Predicted\"\n",
    "p.yaxis.axis_label_text_font_style = \"italic\"\n",
    "p.yaxis.axis_label_text_color = \"#aa6666\"\n",
    "p.background_fill_color = \"beige\"\n",
    "p.background_fill_alpha = 0.5\n",
    "#p.line([Y.min(), Y.max()], [Y.min(), Y.max()], line_dash=\"4 4\", line_width=2, color='red')\n",
    "\n",
    "# create a new plot with the toolbar below\n",
    "# line_dash=\"4 4\", line_width=2, color='red'\n",
    "p.line([Y.min(), Y.max()], [Y.min(), Y.max()], line_dash=\"4 4\", line_width=2, line_color=\"black\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(predicted, (predicted - Y), c='r', s=30)\n",
    "plt.title(\"Residual plot on the training data\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotining using bokeh\n",
    "#TOOLS = 'hover,box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "TOOLS = 'box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
    "p = figure(plot_width=500, plot_height=500, title=\"Residual plot on the training data\", tools=TOOLS)\n",
    "p.scatter(predicted, (predicted - Y),x=\"jjj\", marker=\"o\", color=\"#80B1D3\", line_width=3)\n",
    "p.title.align = \"center\"\n",
    "p.xaxis.axis_label = \"Predicted\"\n",
    "p.xaxis.axis_label_text_color = \"#aa6666\"\n",
    "#p.xaxis.axis_label_standoff = 30\n",
    "p.xaxis.major_tick_line_color = \"firebrick\"\n",
    "p.xaxis.major_tick_line_width = 3\n",
    "p.xaxis.minor_tick_line_color = \"orange\"\n",
    "p.yaxis.axis_label = \"Residuals\"\n",
    "p.yaxis.axis_label_text_font_style = \"italic\"\n",
    "p.yaxis.axis_label_text_color = \"#aa6666\"\n",
    "p.background_fill_color = \"beige\"\n",
    "p.background_fill_alpha = 0.5\n",
    "#p.line([2,38], [0, 0], line_dash=\"4 4\", line_width=2, color='red')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best to deliver the model by pipeline the operation then at deployment can be done in one model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  I used two ways to check the pipeline so any one can be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use Pipeline\n",
    "# ANOVA \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "anova_filter = SelectKBest(f_regression, k=13)\n",
    "LRR = KernelRidge(kernel='rbf', gamma=0.052, alpha =  0.0216)\n",
    "anova_LinReg = Pipeline([('scaler_Input',scaler), ('anova', anova_filter), ('LinReg', LRR)])\n",
    "# You can set the parameters using the names issued\n",
    "# For instance, fit using a k of 10 in the SelectKBest\n",
    "anova_LinReg.set_params(anova__k=13).fit(new_data, Y)\n",
    "prediction = anova_LinReg.predict(new_data)\n",
    "print anova_LinReg.score(new_data, Y)                        \n",
    "# getting the selected features chosen by anova_filter\n",
    "results = cross_validation.cross_val_score(anova_LinReg, new_data, Y, cv=kfold, scoring=scoring)\n",
    "print 'Scoring according to mean_squared_error'\n",
    "print results\n",
    "print '\\n Mean      Standard deviation'\n",
    "print(\"%.2f      %.2f\" % (results.mean(), results.std()))\n",
    "print anova_LinReg.named_steps['anova'].get_support()\n",
    "r_squared = r2_score(Y, prediction, multioutput='variance_weighted')\n",
    "print 'R-squared = ',r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using make_pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# ANOVA SVM-C\n",
    "# 1) anova filter, take 3 best ranked features\n",
    "anova_filter = SelectKBest(f_regression, k=13)\n",
    "anova_KernelRidge = make_pipeline(scaler, anova_filter, LRR)\n",
    "anova_KernelRidge.fit(new_data, Y)\n",
    "prediction = anova_KernelRidge.predict(new_data)\n",
    "r_squared = r2_score(Y, prediction, multioutput='variance_weighted')\n",
    "print 'R-squared = ',r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Pipeline model for developement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the model scaler to the desk\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(anova_KernelRidge, 'anova_KernelRidge.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test the model if it is work\n",
    "anova_KernelRidgeTest = joblib.load('anova_KernelRidge.pkl')\n",
    "NewPred = anova_KernelRidgeTest.predict(new_data)\n",
    "print \" =================================================================>>>>> done\"\n",
    "r_squared = r2_score(Y, NewPred, multioutput='variance_weighted')\n",
    "print 'R-squared = ',r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test on single data point, randomly choose point number 55\n",
    "print 'Point of training data before normalization\\n',new_data[55]\n",
    "print '\\nThe read target of the data = ', Y[55]\n",
    "NewPred = anova_KernelRidgeTest.predict([new_data[55]])\n",
    "print '\\nThe Predicted target of the data = ', NewPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
